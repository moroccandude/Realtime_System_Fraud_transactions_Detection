[2025-03-22T01:59:00.747+0000] {executor_loader.py:258} INFO - Loaded executor: SequentialExecutor
[2025-03-22T01:59:00.791+0000] {scheduler_job_runner.py:950} INFO - Starting the scheduler
[2025-03-22T01:59:00.792+0000] {scheduler_job_runner.py:957} INFO - Processing each file at most -1 times
[2025-03-22T01:59:00.797+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 3880645
[2025-03-22T01:59:00.797+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T01:59:00.799+0000] {settings.py:63} INFO - Configured default timezone UTC
[2025-03-22T01:59:00.814+0000] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2025-03-22T02:00:25.985+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.fetch_data manual__2025-03-22T01:51:54.430740+00:00 [scheduled]>
[2025-03-22T02:00:25.986+0000] {scheduler_job_runner.py:507} INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
[2025-03-22T02:00:25.986+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.fetch_data manual__2025-03-22T01:51:54.430740+00:00 [scheduled]>
[2025-03-22T02:00:25.987+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.fetch_data manual__2025-03-22T01:51:54.430740+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-03-22T02:00:25.987+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='fetch_data', run_id='manual__2025-03-22T01:51:54.430740+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-03-22T02:00:25.988+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'fetch_data', 'manual__2025-03-22T01:51:54.430740+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:25.991+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'fetch_data', 'manual__2025-03-22T01:51:54.430740+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:26.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/usmail/sys_fraud/sys_detection_frauds/system_fraud_transactions_detection/airflow_home/dags/dags.py
[2025-03-22T02:00:27.116+0000] {task_command.py:467} INFO - Running <TaskInstance: fraud_detection_pipeline.fetch_data manual__2025-03-22T01:51:54.430740+00:00 [queued]> on host usmail-ThinkBook-14-G2-ITL
[2025-03-22T02:00:27.638+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='fetch_data', run_id='manual__2025-03-22T01:51:54.430740+00:00', try_number=2, map_index=-1)
[2025-03-22T02:00:27.642+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=fetch_data, run_id=manual__2025-03-22T01:51:54.430740+00:00, map_index=-1, run_start_date=2025-03-22 02:00:27.151114+00:00, run_end_date=2025-03-22 02:00:27.267509+00:00, run_duration=0.116395, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=4, job_id=23, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-03-22 02:00:25.986671+00:00, queued_by_job_id=22, pid=3881657
[2025-03-22T02:00:27.699+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.load_to_hdfs manual__2025-03-22T01:51:54.430740+00:00 [scheduled]>
[2025-03-22T02:00:27.699+0000] {scheduler_job_runner.py:507} INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
[2025-03-22T02:00:27.700+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.load_to_hdfs manual__2025-03-22T01:51:54.430740+00:00 [scheduled]>
[2025-03-22T02:00:27.701+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.load_to_hdfs manual__2025-03-22T01:51:54.430740+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-03-22T02:00:27.701+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='load_to_hdfs', run_id='manual__2025-03-22T01:51:54.430740+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-03-22T02:00:27.701+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'load_to_hdfs', 'manual__2025-03-22T01:51:54.430740+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:27.705+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'load_to_hdfs', 'manual__2025-03-22T01:51:54.430740+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:28.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/usmail/sys_fraud/sys_detection_frauds/system_fraud_transactions_detection/airflow_home/dags/dags.py
[2025-03-22T02:00:28.862+0000] {task_command.py:467} INFO - Running <TaskInstance: fraud_detection_pipeline.load_to_hdfs manual__2025-03-22T01:51:54.430740+00:00 [queued]> on host usmail-ThinkBook-14-G2-ITL
[2025-03-22T02:00:32.112+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='load_to_hdfs', run_id='manual__2025-03-22T01:51:54.430740+00:00', try_number=2, map_index=-1)
[2025-03-22T02:00:32.115+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=load_to_hdfs, run_id=manual__2025-03-22T01:51:54.430740+00:00, map_index=-1, run_start_date=2025-03-22 02:00:28.905152+00:00, run_end_date=2025-03-22 02:00:31.705718+00:00, run_duration=2.800566, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=4, job_id=24, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-03-22 02:00:27.700688+00:00, queued_by_job_id=22, pid=3881683
[2025-03-22T02:00:32.262+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.connect_to_hdfs manual__2025-03-22T01:51:54.430740+00:00 [scheduled]>
[2025-03-22T02:00:32.262+0000] {scheduler_job_runner.py:507} INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
[2025-03-22T02:00:32.262+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.connect_to_hdfs manual__2025-03-22T01:51:54.430740+00:00 [scheduled]>
[2025-03-22T02:00:32.263+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.connect_to_hdfs manual__2025-03-22T01:51:54.430740+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-03-22T02:00:32.263+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='connect_to_hdfs', run_id='manual__2025-03-22T01:51:54.430740+00:00', try_number=3, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-03-22T02:00:32.263+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'connect_to_hdfs', 'manual__2025-03-22T01:51:54.430740+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:32.267+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'connect_to_hdfs', 'manual__2025-03-22T01:51:54.430740+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:33.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/usmail/sys_fraud/sys_detection_frauds/system_fraud_transactions_detection/airflow_home/dags/dags.py
[2025-03-22T02:00:33.354+0000] {task_command.py:467} INFO - Running <TaskInstance: fraud_detection_pipeline.connect_to_hdfs manual__2025-03-22T01:51:54.430740+00:00 [queued]> on host usmail-ThinkBook-14-G2-ITL
[2025-03-22T02:00:33.886+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='connect_to_hdfs', run_id='manual__2025-03-22T01:51:54.430740+00:00', try_number=3, map_index=-1)
[2025-03-22T02:00:33.888+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=connect_to_hdfs, run_id=manual__2025-03-22T01:51:54.430740+00:00, map_index=-1, run_start_date=2025-03-22 02:00:33.390313+00:00, run_end_date=2025-03-22 02:00:33.504378+00:00, run_duration=0.114065, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=3, max_tries=5, job_id=25, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-03-22 02:00:32.262829+00:00, queued_by_job_id=22, pid=3881914
[2025-03-22T02:00:33.937+0000] {dagrun.py:854} INFO - Marking run <DagRun fraud_detection_pipeline @ 2025-03-22 01:51:54.430740+00:00: manual__2025-03-22T01:51:54.430740+00:00, state:running, queued_at: 2025-03-22 01:51:54.439080+00:00. externally triggered: True> successful
[2025-03-22T02:00:33.937+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-03-22 01:51:54.430740+00:00, run_id=manual__2025-03-22T01:51:54.430740+00:00, run_start_date=2025-03-22 01:51:55.400916+00:00, run_end_date=2025-03-22 02:00:33.937851+00:00, run_duration=518.536935, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-03-21 01:51:54.430740+00:00, data_interval_end=2025-03-22 01:51:54.430740+00:00, dag_hash=25b699df499440ee3f9cdb70156336fb
[2025-03-22T02:00:35.015+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.fetch_data scheduled__2025-03-20T00:00:00+00:00 [scheduled]>
[2025-03-22T02:00:35.015+0000] {scheduler_job_runner.py:507} INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
[2025-03-22T02:00:35.015+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.fetch_data scheduled__2025-03-20T00:00:00+00:00 [scheduled]>
[2025-03-22T02:00:35.016+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.fetch_data scheduled__2025-03-20T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-03-22T02:00:35.016+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='fetch_data', run_id='scheduled__2025-03-20T00:00:00+00:00', try_number=4, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-03-22T02:00:35.016+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'fetch_data', 'scheduled__2025-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:35.019+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'fetch_data', 'scheduled__2025-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:35.959+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/usmail/sys_fraud/sys_detection_frauds/system_fraud_transactions_detection/airflow_home/dags/dags.py
[2025-03-22T02:00:36.106+0000] {task_command.py:467} INFO - Running <TaskInstance: fraud_detection_pipeline.fetch_data scheduled__2025-03-20T00:00:00+00:00 [queued]> on host usmail-ThinkBook-14-G2-ITL
[2025-03-22T02:00:36.610+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='fetch_data', run_id='scheduled__2025-03-20T00:00:00+00:00', try_number=4, map_index=-1)
[2025-03-22T02:00:36.612+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=fetch_data, run_id=scheduled__2025-03-20T00:00:00+00:00, map_index=-1, run_start_date=2025-03-22 02:00:36.138366+00:00, run_end_date=2025-03-22 02:00:36.254310+00:00, run_duration=0.115944, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=4, max_tries=6, job_id=26, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-03-22 02:00:35.015823+00:00, queued_by_job_id=22, pid=3881976
[2025-03-22T02:00:36.644+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.load_to_hdfs scheduled__2025-03-20T00:00:00+00:00 [scheduled]>
[2025-03-22T02:00:36.644+0000] {scheduler_job_runner.py:507} INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
[2025-03-22T02:00:36.644+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.load_to_hdfs scheduled__2025-03-20T00:00:00+00:00 [scheduled]>
[2025-03-22T02:00:36.645+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.load_to_hdfs scheduled__2025-03-20T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-03-22T02:00:36.645+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='load_to_hdfs', run_id='scheduled__2025-03-20T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-03-22T02:00:36.646+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'load_to_hdfs', 'scheduled__2025-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:36.649+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'load_to_hdfs', 'scheduled__2025-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:37.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/usmail/sys_fraud/sys_detection_frauds/system_fraud_transactions_detection/airflow_home/dags/dags.py
[2025-03-22T02:00:37.727+0000] {task_command.py:467} INFO - Running <TaskInstance: fraud_detection_pipeline.load_to_hdfs scheduled__2025-03-20T00:00:00+00:00 [queued]> on host usmail-ThinkBook-14-G2-ITL
[2025-03-22T02:00:40.918+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='load_to_hdfs', run_id='scheduled__2025-03-20T00:00:00+00:00', try_number=1, map_index=-1)
[2025-03-22T02:00:40.920+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=load_to_hdfs, run_id=scheduled__2025-03-20T00:00:00+00:00, map_index=-1, run_start_date=2025-03-22 02:00:37.754369+00:00, run_end_date=2025-03-22 02:00:40.573547+00:00, run_duration=2.819178, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=3, job_id=27, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-03-22 02:00:36.644924+00:00, queued_by_job_id=22, pid=3882016
[2025-03-22T02:00:40.966+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.connect_to_hdfs scheduled__2025-03-20T00:00:00+00:00 [scheduled]>
[2025-03-22T02:00:40.966+0000] {scheduler_job_runner.py:507} INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
[2025-03-22T02:00:40.967+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.connect_to_hdfs scheduled__2025-03-20T00:00:00+00:00 [scheduled]>
[2025-03-22T02:00:40.967+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.connect_to_hdfs scheduled__2025-03-20T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-03-22T02:00:40.968+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='connect_to_hdfs', run_id='scheduled__2025-03-20T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-03-22T02:00:40.968+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'connect_to_hdfs', 'scheduled__2025-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:40.971+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'connect_to_hdfs', 'scheduled__2025-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:41.886+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/usmail/sys_fraud/sys_detection_frauds/system_fraud_transactions_detection/airflow_home/dags/dags.py
[2025-03-22T02:00:42.028+0000] {task_command.py:467} INFO - Running <TaskInstance: fraud_detection_pipeline.connect_to_hdfs scheduled__2025-03-20T00:00:00+00:00 [queued]> on host usmail-ThinkBook-14-G2-ITL
[2025-03-22T02:00:42.530+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='connect_to_hdfs', run_id='scheduled__2025-03-20T00:00:00+00:00', try_number=1, map_index=-1)
[2025-03-22T02:00:42.533+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=connect_to_hdfs, run_id=scheduled__2025-03-20T00:00:00+00:00, map_index=-1, run_start_date=2025-03-22 02:00:42.058565+00:00, run_end_date=2025-03-22 02:00:42.173659+00:00, run_duration=0.115094, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=3, job_id=28, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-03-22 02:00:40.967491+00:00, queued_by_job_id=22, pid=3882259
[2025-03-22T02:00:42.557+0000] {dagrun.py:854} INFO - Marking run <DagRun fraud_detection_pipeline @ 2025-03-20 00:00:00+00:00: scheduled__2025-03-20T00:00:00+00:00, state:running, queued_at: 2025-03-22 02:00:25.324593+00:00. externally triggered: False> successful
[2025-03-22T02:00:42.557+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-03-20 00:00:00+00:00, run_id=scheduled__2025-03-20T00:00:00+00:00, run_start_date=2025-03-22 02:00:34.978478+00:00, run_end_date=2025-03-22 02:00:42.557541+00:00, run_duration=7.579063, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-03-20 00:00:00+00:00, data_interval_end=2025-03-21 00:00:00+00:00, dag_hash=25b699df499440ee3f9cdb70156336fb
[2025-03-22T02:00:42.559+0000] {scheduler_job_runner.py:1526} INFO - DAG fraud_detection_pipeline is at (or above) max_active_runs (2 of 1), not creating any more runs
[2025-03-22T02:00:43.606+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.fetch_data scheduled__2025-03-21T00:00:00+00:00 [scheduled]>
[2025-03-22T02:00:43.606+0000] {scheduler_job_runner.py:507} INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
[2025-03-22T02:00:43.607+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.fetch_data scheduled__2025-03-21T00:00:00+00:00 [scheduled]>
[2025-03-22T02:00:43.608+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.fetch_data scheduled__2025-03-21T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-03-22T02:00:43.608+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='fetch_data', run_id='scheduled__2025-03-21T00:00:00+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-03-22T02:00:43.608+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'fetch_data', 'scheduled__2025-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:43.612+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'fetch_data', 'scheduled__2025-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:44.600+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/usmail/sys_fraud/sys_detection_frauds/system_fraud_transactions_detection/airflow_home/dags/dags.py
[2025-03-22T02:00:44.742+0000] {task_command.py:467} INFO - Running <TaskInstance: fraud_detection_pipeline.fetch_data scheduled__2025-03-21T00:00:00+00:00 [queued]> on host usmail-ThinkBook-14-G2-ITL
[2025-03-22T02:00:45.274+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='fetch_data', run_id='scheduled__2025-03-21T00:00:00+00:00', try_number=2, map_index=-1)
[2025-03-22T02:00:45.276+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=fetch_data, run_id=scheduled__2025-03-21T00:00:00+00:00, map_index=-1, run_start_date=2025-03-22 02:00:44.778817+00:00, run_end_date=2025-03-22 02:00:44.893822+00:00, run_duration=0.115005, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=4, job_id=29, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-03-22 02:00:43.607723+00:00, queued_by_job_id=22, pid=3882292
[2025-03-22T02:00:45.312+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.load_to_hdfs scheduled__2025-03-21T00:00:00+00:00 [scheduled]>
[2025-03-22T02:00:45.312+0000] {scheduler_job_runner.py:507} INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
[2025-03-22T02:00:45.313+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.load_to_hdfs scheduled__2025-03-21T00:00:00+00:00 [scheduled]>
[2025-03-22T02:00:45.313+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.load_to_hdfs scheduled__2025-03-21T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-03-22T02:00:45.314+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='load_to_hdfs', run_id='scheduled__2025-03-21T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-03-22T02:00:45.314+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'load_to_hdfs', 'scheduled__2025-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:45.317+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'load_to_hdfs', 'scheduled__2025-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:46.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/usmail/sys_fraud/sys_detection_frauds/system_fraud_transactions_detection/airflow_home/dags/dags.py
[2025-03-22T02:00:46.424+0000] {task_command.py:467} INFO - Running <TaskInstance: fraud_detection_pipeline.load_to_hdfs scheduled__2025-03-21T00:00:00+00:00 [queued]> on host usmail-ThinkBook-14-G2-ITL
[2025-03-22T02:00:49.621+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='load_to_hdfs', run_id='scheduled__2025-03-21T00:00:00+00:00', try_number=1, map_index=-1)
[2025-03-22T02:00:49.624+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=load_to_hdfs, run_id=scheduled__2025-03-21T00:00:00+00:00, map_index=-1, run_start_date=2025-03-22 02:00:46.465079+00:00, run_end_date=2025-03-22 02:00:49.251956+00:00, run_duration=2.786877, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=3, job_id=30, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-03-22 02:00:45.313381+00:00, queued_by_job_id=22, pid=3882336
[2025-03-22T02:00:49.671+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.connect_to_hdfs scheduled__2025-03-21T00:00:00+00:00 [scheduled]>
[2025-03-22T02:00:49.671+0000] {scheduler_job_runner.py:507} INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
[2025-03-22T02:00:49.672+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.connect_to_hdfs scheduled__2025-03-21T00:00:00+00:00 [scheduled]>
[2025-03-22T02:00:49.672+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.connect_to_hdfs scheduled__2025-03-21T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-03-22T02:00:49.673+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='connect_to_hdfs', run_id='scheduled__2025-03-21T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-03-22T02:00:49.673+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'connect_to_hdfs', 'scheduled__2025-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:49.676+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'connect_to_hdfs', 'scheduled__2025-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:50.639+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/usmail/sys_fraud/sys_detection_frauds/system_fraud_transactions_detection/airflow_home/dags/dags.py
[2025-03-22T02:00:50.867+0000] {task_command.py:467} INFO - Running <TaskInstance: fraud_detection_pipeline.connect_to_hdfs scheduled__2025-03-21T00:00:00+00:00 [queued]> on host usmail-ThinkBook-14-G2-ITL
[2025-03-22T02:00:51.573+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='connect_to_hdfs', run_id='scheduled__2025-03-21T00:00:00+00:00', try_number=1, map_index=-1)
[2025-03-22T02:00:51.578+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=connect_to_hdfs, run_id=scheduled__2025-03-21T00:00:00+00:00, map_index=-1, run_start_date=2025-03-22 02:00:50.924154+00:00, run_end_date=2025-03-22 02:00:51.094232+00:00, run_duration=0.170078, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=3, job_id=31, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-03-22 02:00:49.672339+00:00, queued_by_job_id=22, pid=3882566
[2025-03-22T02:00:51.607+0000] {dagrun.py:854} INFO - Marking run <DagRun fraud_detection_pipeline @ 2025-03-21 00:00:00+00:00: scheduled__2025-03-21T00:00:00+00:00, state:running, queued_at: 2025-03-22 02:00:25.324612+00:00. externally triggered: False> successful
[2025-03-22T02:00:51.607+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-03-21 00:00:00+00:00, run_id=scheduled__2025-03-21T00:00:00+00:00, run_start_date=2025-03-22 02:00:43.585463+00:00, run_end_date=2025-03-22 02:00:51.607298+00:00, run_duration=8.021835, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-03-21 00:00:00+00:00, data_interval_end=2025-03-22 00:00:00+00:00, dag_hash=25b699df499440ee3f9cdb70156336fb
[2025-03-22T02:00:51.608+0000] {scheduler_job_runner.py:1526} INFO - DAG fraud_detection_pipeline is at (or above) max_active_runs (1 of 1), not creating any more runs
[2025-03-22T02:00:52.582+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.fetch_data manual__2025-03-22T01:21:02.990581+00:00 [scheduled]>
[2025-03-22T02:00:52.582+0000] {scheduler_job_runner.py:507} INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
[2025-03-22T02:00:52.583+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.fetch_data manual__2025-03-22T01:21:02.990581+00:00 [scheduled]>
[2025-03-22T02:00:52.584+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.fetch_data manual__2025-03-22T01:21:02.990581+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-03-22T02:00:52.584+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='fetch_data', run_id='manual__2025-03-22T01:21:02.990581+00:00', try_number=3, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-03-22T02:00:52.585+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'fetch_data', 'manual__2025-03-22T01:21:02.990581+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:52.588+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'fetch_data', 'manual__2025-03-22T01:21:02.990581+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:53.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/usmail/sys_fraud/sys_detection_frauds/system_fraud_transactions_detection/airflow_home/dags/dags.py
[2025-03-22T02:00:53.754+0000] {task_command.py:467} INFO - Running <TaskInstance: fraud_detection_pipeline.fetch_data manual__2025-03-22T01:21:02.990581+00:00 [queued]> on host usmail-ThinkBook-14-G2-ITL
[2025-03-22T02:00:54.299+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='fetch_data', run_id='manual__2025-03-22T01:21:02.990581+00:00', try_number=3, map_index=-1)
[2025-03-22T02:00:54.302+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=fetch_data, run_id=manual__2025-03-22T01:21:02.990581+00:00, map_index=-1, run_start_date=2025-03-22 02:00:53.789698+00:00, run_end_date=2025-03-22 02:00:53.936716+00:00, run_duration=0.147018, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=3, max_tries=5, job_id=32, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-03-22 02:00:52.583677+00:00, queued_by_job_id=22, pid=3882638
[2025-03-22T02:00:54.338+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.load_to_hdfs manual__2025-03-22T01:21:02.990581+00:00 [scheduled]>
[2025-03-22T02:00:54.338+0000] {scheduler_job_runner.py:507} INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
[2025-03-22T02:00:54.338+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.load_to_hdfs manual__2025-03-22T01:21:02.990581+00:00 [scheduled]>
[2025-03-22T02:00:54.339+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.load_to_hdfs manual__2025-03-22T01:21:02.990581+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-03-22T02:00:54.340+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='load_to_hdfs', run_id='manual__2025-03-22T01:21:02.990581+00:00', try_number=4, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-03-22T02:00:54.340+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'load_to_hdfs', 'manual__2025-03-22T01:21:02.990581+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:54.343+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'load_to_hdfs', 'manual__2025-03-22T01:21:02.990581+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:55.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/usmail/sys_fraud/sys_detection_frauds/system_fraud_transactions_detection/airflow_home/dags/dags.py
[2025-03-22T02:00:55.408+0000] {task_command.py:467} INFO - Running <TaskInstance: fraud_detection_pipeline.load_to_hdfs manual__2025-03-22T01:21:02.990581+00:00 [queued]> on host usmail-ThinkBook-14-G2-ITL
[2025-03-22T02:00:58.820+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='load_to_hdfs', run_id='manual__2025-03-22T01:21:02.990581+00:00', try_number=4, map_index=-1)
[2025-03-22T02:00:58.824+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=load_to_hdfs, run_id=manual__2025-03-22T01:21:02.990581+00:00, map_index=-1, run_start_date=2025-03-22 02:00:55.438398+00:00, run_end_date=2025-03-22 02:00:58.418762+00:00, run_duration=2.980364, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=4, max_tries=6, job_id=33, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-03-22 02:00:54.339262+00:00, queued_by_job_id=22, pid=3882650
[2025-03-22T02:00:58.897+0000] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: fraud_detection_pipeline.connect_to_hdfs manual__2025-03-22T01:21:02.990581+00:00 [scheduled]>
[2025-03-22T02:00:58.897+0000] {scheduler_job_runner.py:507} INFO - DAG fraud_detection_pipeline has 0/16 running and queued tasks
[2025-03-22T02:00:58.897+0000] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: fraud_detection_pipeline.connect_to_hdfs manual__2025-03-22T01:21:02.990581+00:00 [scheduled]>
[2025-03-22T02:00:58.898+0000] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: fraud_detection_pipeline.connect_to_hdfs manual__2025-03-22T01:21:02.990581+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-03-22T02:00:58.899+0000] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='connect_to_hdfs', run_id='manual__2025-03-22T01:21:02.990581+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-03-22T02:00:58.899+0000] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'connect_to_hdfs', 'manual__2025-03-22T01:21:02.990581+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:58.902+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'fraud_detection_pipeline', 'connect_to_hdfs', 'manual__2025-03-22T01:21:02.990581+00:00', '--local', '--subdir', 'DAGS_FOLDER/dags.py']
[2025-03-22T02:00:59.948+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/usmail/sys_fraud/sys_detection_frauds/system_fraud_transactions_detection/airflow_home/dags/dags.py
[2025-03-22T02:01:00.087+0000] {task_command.py:467} INFO - Running <TaskInstance: fraud_detection_pipeline.connect_to_hdfs manual__2025-03-22T01:21:02.990581+00:00 [queued]> on host usmail-ThinkBook-14-G2-ITL
[2025-03-22T02:01:00.661+0000] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='fraud_detection_pipeline', task_id='connect_to_hdfs', run_id='manual__2025-03-22T01:21:02.990581+00:00', try_number=1, map_index=-1)
[2025-03-22T02:01:00.663+0000] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=fraud_detection_pipeline, task_id=connect_to_hdfs, run_id=manual__2025-03-22T01:21:02.990581+00:00, map_index=-1, run_start_date=2025-03-22 02:01:00.126611+00:00, run_end_date=2025-03-22 02:01:00.248492+00:00, run_duration=0.121881, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=3, job_id=34, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-03-22 02:00:58.898166+00:00, queued_by_job_id=22, pid=3882895
[2025-03-22T02:01:00.690+0000] {dagrun.py:854} INFO - Marking run <DagRun fraud_detection_pipeline @ 2025-03-22 01:21:02.990581+00:00: manual__2025-03-22T01:21:02.990581+00:00, state:running, queued_at: 2025-03-22 02:00:25.324525+00:00. externally triggered: True> successful
[2025-03-22T02:01:00.691+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=fraud_detection_pipeline, execution_date=2025-03-22 01:21:02.990581+00:00, run_id=manual__2025-03-22T01:21:02.990581+00:00, run_start_date=2025-03-22 02:00:52.556788+00:00, run_end_date=2025-03-22 02:01:00.691234+00:00, run_duration=8.134446, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-03-21 01:21:02.990581+00:00, data_interval_end=2025-03-22 01:21:02.990581+00:00, dag_hash=25b699df499440ee3f9cdb70156336fb
[2025-03-22T02:04:00.850+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T02:09:00.885+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T02:14:00.930+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T02:19:00.974+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T02:24:01.019+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T02:29:01.058+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T02:34:01.084+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T02:50:14.640+0000] {job.py:229} INFO - Heartbeat recovered after 869.98 seconds
[2025-03-22T02:53:28.221+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T02:58:28.278+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T03:03:28.335+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T03:08:28.394+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T03:13:28.448+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T03:18:28.479+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T03:23:28.527+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T03:28:28.577+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T03:33:28.628+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T03:38:28.686+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T03:43:28.739+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T03:48:28.791+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T03:53:28.843+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T03:58:28.864+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T04:03:28.926+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T04:08:28.976+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T04:13:29.026+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T04:18:29.077+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T04:23:29.167+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T04:28:29.218+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T04:33:29.269+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T04:38:29.318+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T04:43:29.367+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T04:57:44.748+0000] {job.py:229} INFO - Heartbeat recovered after 794.17 seconds
[2025-03-22T05:01:38.628+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T05:06:38.680+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T05:11:38.703+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-03-22T05:16:38.756+0000] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
